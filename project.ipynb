{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T15:56:21.471314Z",
     "iopub.status.busy": "2025-08-15T15:56:21.470553Z",
     "iopub.status.idle": "2025-08-15T15:56:30.236386Z",
     "shell.execute_reply": "2025-08-15T15:56:30.235563Z",
     "shell.execute_reply.started": "2025-08-15T15:56:21.471256Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Multi-Source Sales Data Pipeline & Business Insights Dashboard\n",
    "# Author: Data Science Project\n",
    "# Date: August 2025\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import warnings\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "from pathlib import Path\n",
    "import argparse\n",
    "import sys\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class SalesDataPipeline:\n",
    "    \"\"\"\n",
    "    Enterprise-level sales data pipeline for data integration, \n",
    "    transformation, analysis, and reporting.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data_dir=\"data\", output_dir=\"output\"):\n",
    "        self.data_dir = Path(data_dir)\n",
    "        self.output_dir = Path(output_dir)\n",
    "        self.raw_data = {}\n",
    "        self.cleaned_data = None\n",
    "        self.integrated_data = None\n",
    "        \n",
    "        # Create directories if they don't exist\n",
    "        self.data_dir.mkdir(exist_ok=True)\n",
    "        self.output_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        # Set plotting style\n",
    "        plt.style.use('seaborn-v0_8')\n",
    "        sns.set_palette(\"husl\")\n",
    "    \n",
    "    def generate_sample_data(self):\n",
    "        \"\"\"Generate sample data in different formats (CSV, JSON, Excel)\"\"\"\n",
    "        print(\"🔄 Generating sample datasets...\")\n",
    "        \n",
    "        # Generate date range\n",
    "        start_date = datetime(2023, 1, 1)\n",
    "        end_date = datetime(2024, 12, 31)\n",
    "        date_range = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "        \n",
    "        # Product categories and regions\n",
    "        products = ['Laptop', 'Desktop', 'Monitor', 'Keyboard', 'Mouse', 'Tablet', 'Phone', 'Headphones']\n",
    "        regions = ['North America', 'Europe', 'Asia Pacific', 'Latin America', 'Middle East']\n",
    "        sales_reps = [f'Rep_{i:03d}' for i in range(1, 51)]\n",
    "        \n",
    "        # 1. Generate CSV data (Primary sales data)\n",
    "        csv_data = []\n",
    "        for _ in range(5000):\n",
    "            record = {\n",
    "                'transaction_id': f'TXN_{random.randint(100000, 999999)}',\n",
    "                'date': random.choice(date_range).strftime('%Y-%m-%d'),\n",
    "                'product': random.choice(products),\n",
    "                'quantity': random.randint(1, 10),\n",
    "                'unit_price': round(random.uniform(50, 2000), 2),\n",
    "                'region': random.choice(regions),\n",
    "                'sales_rep': random.choice(sales_reps)\n",
    "            }\n",
    "            record['total_amount'] = record['quantity'] * record['unit_price']\n",
    "            csv_data.append(record)\n",
    "        \n",
    "        df_csv = pd.DataFrame(csv_data)\n",
    "        df_csv.to_csv(self.data_dir / 'sales_data.csv', index=False)\n",
    "        \n",
    "        # 2. Generate JSON data (Customer information)\n",
    "        json_data = []\n",
    "        for i in range(2000):\n",
    "            customer = {\n",
    "                'customer_id': f'CUST_{i:06d}',\n",
    "                'customer_name': f'Company_{i}',\n",
    "                'customer_type': random.choice(['Enterprise', 'SMB', 'Individual']),\n",
    "                'registration_date': random.choice(date_range).strftime('%Y-%m-%d'),\n",
    "                'credit_limit': random.randint(1000, 50000),\n",
    "                'region': random.choice(regions),\n",
    "                'industry': random.choice(['Technology', 'Healthcare', 'Finance', 'Manufacturing', 'Retail'])\n",
    "            }\n",
    "            json_data.append(customer)\n",
    "        \n",
    "        with open(self.data_dir / 'customer_data.json', 'w') as f:\n",
    "            json.dump(json_data, f, indent=2)\n",
    "        \n",
    "        # 3. Generate Excel data (Product information with some missing values)\n",
    "        excel_data = []\n",
    "        for product in products:\n",
    "            for i in range(3):  # 3 variants per product\n",
    "                record = {\n",
    "                    'product_id': f'{product[:3].upper()}_{i:03d}',\n",
    "                    'product_name': f'{product} {[\"Basic\", \"Pro\", \"Premium\"][i]}',\n",
    "                    'category': 'Electronics',\n",
    "                    'cost_price': round(random.uniform(30, 1500), 2) if random.random() > 0.1 else None,\n",
    "                    'launch_date': random.choice(date_range[:365]).strftime('%Y-%m-%d'),\n",
    "                    'discontinued': random.choice([True, False]) if random.random() > 0.8 else False,\n",
    "                    'warranty_months': random.choice([12, 24, 36]) if random.random() > 0.05 else None\n",
    "                }\n",
    "                excel_data.append(record)\n",
    "        \n",
    "        df_excel = pd.DataFrame(excel_data)\n",
    "        df_excel.to_excel(self.data_dir / 'product_info.xlsx', index=False)\n",
    "        \n",
    "        print(f\"✅ Sample data generated successfully in '{self.data_dir}' directory\")\n",
    "        print(f\"   - CSV: {len(df_csv)} sales records\")\n",
    "        print(f\"   - JSON: {len(json_data)} customer records\")\n",
    "        print(f\"   - Excel: {len(df_excel)} product records\")\n",
    "    \n",
    "    def load_data(self):\n",
    "        \"\"\"Load data from multiple sources\"\"\"\n",
    "        print(\"\\n🔄 Loading data from multiple sources...\")\n",
    "        \n",
    "        try:\n",
    "            # Load CSV data\n",
    "            self.raw_data['sales'] = pd.read_csv(self.data_dir / 'sales_data.csv')\n",
    "            print(f\"✅ CSV loaded: {len(self.raw_data['sales'])} records\")\n",
    "            \n",
    "            # Load JSON data\n",
    "            with open(self.data_dir / 'customer_data.json', 'r') as f:\n",
    "                json_data = json.load(f)\n",
    "            self.raw_data['customers'] = pd.DataFrame(json_data)\n",
    "            print(f\"✅ JSON loaded: {len(self.raw_data['customers'])} records\")\n",
    "            \n",
    "            # Load Excel data\n",
    "            self.raw_data['products'] = pd.read_excel(self.data_dir / 'product_info.xlsx')\n",
    "            print(f\"✅ Excel loaded: {len(self.raw_data['products'])} records\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error loading data: {e}\")\n",
    "            return False\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def clean_data(self):\n",
    "        \"\"\"Clean and validate data from all sources\"\"\"\n",
    "        print(\"\\n🔄 Cleaning and validating data...\")\n",
    "        \n",
    "        cleaned = {}\n",
    "        \n",
    "        # Clean sales data\n",
    "        sales_df = self.raw_data['sales'].copy()\n",
    "        \n",
    "        # Convert date column\n",
    "        sales_df['date'] = pd.to_datetime(sales_df['date'])\n",
    "        \n",
    "        # Handle missing values in sales data\n",
    "        initial_sales_count = len(sales_df)\n",
    "        sales_df = sales_df.dropna(subset=['transaction_id', 'date', 'product'])\n",
    "        \n",
    "        # Remove duplicates\n",
    "        sales_df = sales_df.drop_duplicates(subset=['transaction_id'])\n",
    "        \n",
    "        # Validate numeric columns\n",
    "        sales_df = sales_df[sales_df['quantity'] > 0]\n",
    "        sales_df = sales_df[sales_df['unit_price'] > 0]\n",
    "        \n",
    "        # Recalculate total_amount to ensure consistency\n",
    "        sales_df['total_amount'] = sales_df['quantity'] * sales_df['unit_price']\n",
    "        \n",
    "        cleaned['sales'] = sales_df\n",
    "        print(f\"   Sales data: {initial_sales_count} → {len(sales_df)} records after cleaning\")\n",
    "        \n",
    "        # Clean customer data\n",
    "        customers_df = self.raw_data['customers'].copy()\n",
    "        customers_df['registration_date'] = pd.to_datetime(customers_df['registration_date'])\n",
    "        customers_df = customers_df.dropna(subset=['customer_id'])\n",
    "        customers_df = customers_df.drop_duplicates(subset=['customer_id'])\n",
    "        \n",
    "        cleaned['customers'] = customers_df\n",
    "        print(f\"   Customer data: {len(self.raw_data['customers'])} → {len(customers_df)} records after cleaning\")\n",
    "        \n",
    "        # Clean product data\n",
    "        products_df = self.raw_data['products'].copy()\n",
    "        products_df['launch_date'] = pd.to_datetime(products_df['launch_date'])\n",
    "        \n",
    "        # Handle missing values in cost_price (use median imputation)\n",
    "        median_cost = products_df['cost_price'].median()\n",
    "        products_df['cost_price'] = products_df['cost_price'].fillna(median_cost)\n",
    "        \n",
    "        # Handle missing warranty_months (use mode imputation)\n",
    "        mode_warranty = products_df['warranty_months'].mode()[0]\n",
    "        products_df['warranty_months'] = products_df['warranty_months'].fillna(mode_warranty)\n",
    "        \n",
    "        # Fill discontinued field\n",
    "        products_df['discontinued'] = products_df['discontinued'].fillna(False)\n",
    "        \n",
    "        cleaned['products'] = products_df\n",
    "        print(f\"   Product data: {len(self.raw_data['products'])} → {len(products_df)} records after cleaning\")\n",
    "        \n",
    "        self.cleaned_data = cleaned\n",
    "        return True\n",
    "    \n",
    "    def integrate_data(self):\n",
    "        \"\"\"Integrate cleaned data from multiple sources\"\"\"\n",
    "        print(\"\\n🔄 Integrating data from multiple sources...\")\n",
    "        \n",
    "        # Start with sales data as the base\n",
    "        integrated_df = self.cleaned_data['sales'].copy()\n",
    "        \n",
    "        # Add customer information (simulate relationship)\n",
    "        # For demo purposes, randomly assign customers to sales records\n",
    "        customer_ids = self.cleaned_data['customers']['customer_id'].tolist()\n",
    "        integrated_df['customer_id'] = np.random.choice(customer_ids, size=len(integrated_df))\n",
    "        \n",
    "        # Merge with customer data\n",
    "        integrated_df = integrated_df.merge(\n",
    "            self.cleaned_data['customers'][['customer_id', 'customer_name', 'customer_type', 'industry']],\n",
    "            on='customer_id',\n",
    "            how='left'\n",
    "        )\n",
    "        \n",
    "        # Add product information (simulate relationship)\n",
    "        # Map product names to product IDs\n",
    "        product_mapping = {}\n",
    "        for _, row in self.cleaned_data['products'].iterrows():\n",
    "            base_product = row['product_name'].split()[0]  # Get base product name\n",
    "            if base_product not in product_mapping:\n",
    "                product_mapping[base_product] = row['product_id']\n",
    "        \n",
    "        integrated_df['product_id'] = integrated_df['product'].map(product_mapping)\n",
    "        \n",
    "        # Merge with product data\n",
    "        integrated_df = integrated_df.merge(\n",
    "            self.cleaned_data['products'][['product_id', 'category', 'cost_price', 'warranty_months']],\n",
    "            on='product_id',\n",
    "            how='left'\n",
    "        )\n",
    "        \n",
    "        # Calculate profit margin\n",
    "        integrated_df['profit'] = integrated_df['total_amount'] - (integrated_df['quantity'] * integrated_df['cost_price'])\n",
    "        integrated_df['profit_margin'] = (integrated_df['profit'] / integrated_df['total_amount']) * 100\n",
    "        \n",
    "        # Add derived columns\n",
    "        integrated_df['year'] = integrated_df['date'].dt.year\n",
    "        integrated_df['month'] = integrated_df['date'].dt.month\n",
    "        integrated_df['quarter'] = integrated_df['date'].dt.quarter\n",
    "        integrated_df['day_of_week'] = integrated_df['date'].dt.day_name()\n",
    "        \n",
    "        self.integrated_data = integrated_df\n",
    "        print(f\"✅ Data integration completed: {len(integrated_df)} records with {integrated_df.shape[1]} columns\")\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def perform_eda(self):\n",
    "        \"\"\"Perform comprehensive Exploratory Data Analysis\"\"\"\n",
    "        print(\"\\n🔄 Performing Exploratory Data Analysis...\")\n",
    "        \n",
    "        df = self.integrated_data\n",
    "        \n",
    "        # Basic statistics\n",
    "        print(\"\\n📊 Dataset Overview:\")\n",
    "        print(f\"Total Records: {len(df):,}\")\n",
    "        print(f\"Date Range: {df['date'].min().strftime('%Y-%m-%d')} to {df['date'].max().strftime('%Y-%m-%d')}\")\n",
    "        print(f\"Total Revenue: ${df['total_amount'].sum():,.2f}\")\n",
    "        print(f\"Average Order Value: ${df['total_amount'].mean():.2f}\")\n",
    "        print(f\"Total Profit: ${df['profit'].sum():,.2f}\")\n",
    "        \n",
    "        # Create visualizations\n",
    "        fig = plt.figure(figsize=(20, 15))\n",
    "        \n",
    "        # 1. Monthly Sales Trend\n",
    "        plt.subplot(3, 3, 1)\n",
    "        monthly_sales = df.groupby([df['date'].dt.to_period('M')])['total_amount'].sum()\n",
    "        monthly_sales.plot(kind='line', marker='o')\n",
    "        plt.title('Monthly Sales Trend', fontsize=14, fontweight='bold')\n",
    "        plt.xlabel('Month')\n",
    "        plt.ylabel('Sales Amount ($)')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 2. Regional Sales Distribution\n",
    "        plt.subplot(3, 3, 2)\n",
    "        regional_sales = df.groupby('region')['total_amount'].sum().sort_values(ascending=True)\n",
    "        regional_sales.plot(kind='barh', color='skyblue')\n",
    "        plt.title('Sales by Region', fontsize=14, fontweight='bold')\n",
    "        plt.xlabel('Sales Amount ($)')\n",
    "        \n",
    "        # 3. Product Performance\n",
    "        plt.subplot(3, 3, 3)\n",
    "        product_sales = df.groupby('product')['total_amount'].sum().sort_values(ascending=False)\n",
    "        product_sales.plot(kind='bar', color='lightcoral')\n",
    "        plt.title('Product Sales Performance', fontsize=14, fontweight='bold')\n",
    "        plt.xlabel('Product')\n",
    "        plt.ylabel('Sales Amount ($)')\n",
    "        plt.xticks(rotation=45)\n",
    "        \n",
    "        # 4. Customer Type Analysis\n",
    "        plt.subplot(3, 3, 4)\n",
    "        customer_type_sales = df.groupby('customer_type')['total_amount'].sum()\n",
    "        plt.pie(customer_type_sales.values, labels=customer_type_sales.index, autopct='%1.1f%%', startangle=90)\n",
    "        plt.title('Sales by Customer Type', fontsize=14, fontweight='bold')\n",
    "        \n",
    "        # 5. Quarterly Performance\n",
    "        plt.subplot(3, 3, 5)\n",
    "        quarterly_sales = df.groupby(['year', 'quarter'])['total_amount'].sum().reset_index()\n",
    "        quarterly_sales['period'] = quarterly_sales['year'].astype(str) + '-Q' + quarterly_sales['quarter'].astype(str)\n",
    "        plt.bar(quarterly_sales['period'], quarterly_sales['total_amount'], color='lightgreen')\n",
    "        plt.title('Quarterly Sales Performance', fontsize=14, fontweight='bold')\n",
    "        plt.xlabel('Quarter')\n",
    "        plt.ylabel('Sales Amount ($)')\n",
    "        plt.xticks(rotation=45)\n",
    "        \n",
    "        # 6. Profit Margin Distribution\n",
    "        plt.subplot(3, 3, 6)\n",
    "        plt.hist(df['profit_margin'], bins=30, color='gold', alpha=0.7, edgecolor='black')\n",
    "        plt.title('Profit Margin Distribution', fontsize=14, fontweight='bold')\n",
    "        plt.xlabel('Profit Margin (%)')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 7. Sales by Day of Week\n",
    "        plt.subplot(3, 3, 7)\n",
    "        dow_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "        dow_sales = df.groupby('day_of_week')['total_amount'].sum().reindex(dow_order)\n",
    "        dow_sales.plot(kind='bar', color='orange')\n",
    "        plt.title('Sales by Day of Week', fontsize=14, fontweight='bold')\n",
    "        plt.xlabel('Day of Week')\n",
    "        plt.ylabel('Sales Amount ($)')\n",
    "        plt.xticks(rotation=45)\n",
    "        \n",
    "        # 8. Industry Performance\n",
    "        plt.subplot(3, 3, 8)\n",
    "        industry_sales = df.groupby('industry')['total_amount'].sum().sort_values(ascending=True)\n",
    "        industry_sales.plot(kind='barh', color='purple', alpha=0.7)\n",
    "        plt.title('Sales by Industry', fontsize=14, fontweight='bold')\n",
    "        plt.xlabel('Sales Amount ($)')\n",
    "        \n",
    "        # 9. Correlation Heatmap\n",
    "        plt.subplot(3, 3, 9)\n",
    "        numeric_cols = ['quantity', 'unit_price', 'total_amount', 'cost_price', 'profit', 'profit_margin']\n",
    "        correlation_matrix = df[numeric_cols].corr()\n",
    "        sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, square=True)\n",
    "        plt.title('Correlation Matrix', fontsize=14, fontweight='bold')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.output_dir / 'sales_dashboard.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"✅ EDA completed. Dashboard saved to '{self.output_dir}/sales_dashboard.png'\")\n",
    "    \n",
    "    def generate_insights_report(self):\n",
    "        \"\"\"Generate detailed insights and key metrics\"\"\"\n",
    "        print(\"\\n🔄 Generating business insights report...\")\n",
    "        \n",
    "        df = self.integrated_data\n",
    "        \n",
    "        insights = []\n",
    "        \n",
    "        # Revenue insights\n",
    "        total_revenue = df['total_amount'].sum()\n",
    "        total_profit = df['profit'].sum()\n",
    "        overall_margin = (total_profit / total_revenue) * 100\n",
    "        \n",
    "        insights.append(f\"📈 Total Revenue: ${total_revenue:,.2f}\")\n",
    "        insights.append(f\"💰 Total Profit: ${total_profit:,.2f}\")\n",
    "        insights.append(f\"📊 Overall Profit Margin: {overall_margin:.2f}%\")\n",
    "        \n",
    "        # Top performers\n",
    "        top_region = df.groupby('region')['total_amount'].sum().idxmax()\n",
    "        top_product = df.groupby('product')['total_amount'].sum().idxmax()\n",
    "        top_customer_type = df.groupby('customer_type')['total_amount'].sum().idxmax()\n",
    "        \n",
    "        insights.append(f\"\\n🏆 Top Performing Region: {top_region}\")\n",
    "        insights.append(f\"🏆 Best Selling Product: {top_product}\")\n",
    "        insights.append(f\"🏆 Most Valuable Customer Type: {top_customer_type}\")\n",
    "        \n",
    "        # Seasonal trends\n",
    "        monthly_avg = df.groupby(df['date'].dt.month)['total_amount'].mean()\n",
    "        best_month = monthly_avg.idxmax()\n",
    "        worst_month = monthly_avg.idxmin()\n",
    "        \n",
    "        insights.append(f\"\\n📅 Best Performing Month: {pd.to_datetime(f'2024-{best_month:02d}-01').strftime('%B')}\")\n",
    "        insights.append(f\"📅 Lowest Performing Month: {pd.to_datetime(f'2024-{worst_month:02d}-01').strftime('%B')}\")\n",
    "        \n",
    "        # Growth analysis\n",
    "        df_sorted = df.sort_values('date')\n",
    "        first_half = df_sorted[df_sorted['date'] < '2024-07-01']['total_amount'].sum()\n",
    "        second_half = df_sorted[df_sorted['date'] >= '2024-07-01']['total_amount'].sum()\n",
    "        growth_rate = ((second_half - first_half) / first_half) * 100 if first_half > 0 else 0\n",
    "        \n",
    "        insights.append(f\"\\n📈 H2 vs H1 Growth Rate: {growth_rate:.2f}%\")\n",
    "        \n",
    "        # Save insights to file\n",
    "        with open(self.output_dir / 'business_insights.txt', 'w') as f:\n",
    "            f.write(\"BUSINESS INSIGHTS REPORT\\n\")\n",
    "            f.write(\"=\" * 50 + \"\\n\\n\")\n",
    "            for insight in insights:\n",
    "                f.write(insight + \"\\n\")\n",
    "        \n",
    "        # Print insights\n",
    "        print(\"\\n📋 Key Business Insights:\")\n",
    "        for insight in insights:\n",
    "            print(insight)\n",
    "        \n",
    "        return insights\n",
    "    \n",
    "    def export_reports(self):\n",
    "        \"\"\"Export summary reports in various formats\"\"\"\n",
    "        print(\"\\n🔄 Exporting summary reports...\")\n",
    "        \n",
    "        df = self.integrated_data\n",
    "        \n",
    "        # 1. Monthly Summary CSV\n",
    "        monthly_summary = df.groupby([df['date'].dt.to_period('M')]).agg({\n",
    "            'total_amount': ['sum', 'mean', 'count'],\n",
    "            'profit': 'sum',\n",
    "            'quantity': 'sum'\n",
    "        }).round(2)\n",
    "        \n",
    "        monthly_summary.columns = ['Total_Sales', 'Avg_Order_Value', 'Order_Count', 'Total_Profit', 'Units_Sold']\n",
    "        monthly_summary.to_csv(self.output_dir / 'monthly_summary.csv')\n",
    "        \n",
    "        # 2. Regional Performance CSV\n",
    "        regional_summary = df.groupby('region').agg({\n",
    "            'total_amount': 'sum',\n",
    "            'profit': 'sum',\n",
    "            'quantity': 'sum',\n",
    "            'transaction_id': 'count'\n",
    "        }).round(2)\n",
    "        \n",
    "        regional_summary.columns = ['Total_Sales', 'Total_Profit', 'Units_Sold', 'Order_Count']\n",
    "        regional_summary['Profit_Margin'] = (regional_summary['Total_Profit'] / regional_summary['Total_Sales'] * 100).round(2)\n",
    "        regional_summary.to_csv(self.output_dir / 'regional_performance.csv')\n",
    "        \n",
    "        # 3. Product Analysis CSV\n",
    "        product_summary = df.groupby('product').agg({\n",
    "            'total_amount': 'sum',\n",
    "            'profit': 'sum',\n",
    "            'quantity': 'sum',\n",
    "            'unit_price': 'mean'\n",
    "        }).round(2)\n",
    "        \n",
    "        product_summary.columns = ['Total_Sales', 'Total_Profit', 'Units_Sold', 'Avg_Price']\n",
    "        product_summary['Profit_Margin'] = (product_summary['Total_Profit'] / product_summary['Total_Sales'] * 100).round(2)\n",
    "        product_summary.to_csv(self.output_dir / 'product_analysis.csv')\n",
    "        \n",
    "        # 4. Executive Summary CSV\n",
    "        executive_summary = pd.DataFrame({\n",
    "            'Metric': [\n",
    "                'Total Revenue',\n",
    "                'Total Profit', \n",
    "                'Total Orders',\n",
    "                'Average Order Value',\n",
    "                'Overall Profit Margin (%)',\n",
    "                'Total Customers',\n",
    "                'Top Region',\n",
    "                'Best Product'\n",
    "            ],\n",
    "            'Value': [\n",
    "                f\"${df['total_amount'].sum():,.2f}\",\n",
    "                f\"${df['profit'].sum():,.2f}\",\n",
    "                len(df),\n",
    "                f\"${df['total_amount'].mean():.2f}\",\n",
    "                f\"{(df['profit'].sum() / df['total_amount'].sum() * 100):.2f}%\",\n",
    "                df['customer_id'].nunique(),\n",
    "                df.groupby('region')['total_amount'].sum().idxmax(),\n",
    "                df.groupby('product')['total_amount'].sum().idxmax()\n",
    "            ]\n",
    "        })\n",
    "        \n",
    "        executive_summary.to_csv(self.output_dir / 'executive_summary.csv', index=False)\n",
    "        \n",
    "        print(\"✅ Reports exported successfully:\")\n",
    "        print(f\"   - Monthly Summary: monthly_summary.csv\")\n",
    "        print(f\"   - Regional Performance: regional_performance.csv\") \n",
    "        print(f\"   - Product Analysis: product_analysis.csv\")\n",
    "        print(f\"   - Executive Summary: executive_summary.csv\")\n",
    "    \n",
    "    def run_pipeline(self, generate_data=False):\n",
    "        \"\"\"Run the complete data pipeline\"\"\"\n",
    "        print(\"🚀 Starting Multi-Source Sales Data Pipeline...\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        try:\n",
    "            # Generate sample data if requested\n",
    "            if generate_data:\n",
    "                self.generate_sample_data()\n",
    "            \n",
    "            # Execute pipeline steps\n",
    "            if not self.load_data():\n",
    "                return False\n",
    "            \n",
    "            if not self.clean_data():\n",
    "                return False\n",
    "            \n",
    "            if not self.integrate_data():\n",
    "                return False\n",
    "            \n",
    "            self.perform_eda()\n",
    "            self.generate_insights_report()\n",
    "            self.export_reports()\n",
    "            \n",
    "            print(\"\\n\" + \"=\" * 60)\n",
    "            print(\"🎉 Pipeline completed successfully!\")\n",
    "            print(f\"📁 All outputs saved to: {self.output_dir}\")\n",
    "            \n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\n❌ Pipeline failed with error: {e}\")\n",
    "            return False\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function with command line interface\"\"\"\n",
    "    parser = argparse.ArgumentParser(description='Multi-Source Sales Data Pipeline')\n",
    "    parser.add_argument('--generate-data', action='store_true', \n",
    "                       help='Generate sample data files')\n",
    "    parser.add_argument('--data-dir', default='data',\n",
    "                       help='Directory containing input data files')\n",
    "    parser.add_argument('--output-dir', default='output',\n",
    "                       help='Directory for output files')\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    # Initialize and run pipeline\n",
    "    pipeline = SalesDataPipeline(data_dir=args.data_dir, output_dir=args.output_dir)\n",
    "    success = pipeline.run_pipeline(generate_data=args.generate_data)\n",
    "    \n",
    "    sys.exit(0 if success else 1)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # For demonstration, run with data generation\n",
    "    pipeline = SalesDataPipeline()\n",
    "    pipeline.run_pipeline(generate_data=True)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
